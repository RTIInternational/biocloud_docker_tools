import argparse
import boto3
import json
import re
import os

# Get arguments
parser = argparse.ArgumentParser()
parser.add_argument(
    '--outputs_json',
    help='S3 path to outputs.json file generated by workflow run',
    type = str,
    required = True
)
parser.add_argument(
    '--target_dir',
    help='Target local or S3 dir for results',
    type = str,
    required = True
)
parser.add_argument(
    '--aws_access_key_id',
    help='AWS access key ID for profile used to run workflow',
    type = str,
    required = True
)
parser.add_argument(
    '--aws_secret_access_key',
    help='AWS secret access key ID for profile used to run workflow',
    type = str,
    required = True
)
parser.add_argument(
    '--aws_region_name',
    help='AWS region in which to run workflow',
    type = str,
    required = True
)
args = parser.parse_args()

def split_s3_path(s3_path):
    path_parts=s3_path.replace("s3://","").split("/")
    bucket=path_parts.pop(0)
    key="/".join(path_parts)
    return bucket, key

def traverse(o, tree_types=(list, tuple)):
    if isinstance(o, tree_types):
        for value in o:
            for subvalue in traverse(value, tree_types):
                yield subvalue
    else:
        yield o

def retrieve_file(source_file, target_dir):
    target_dir = target_dir if (target_dir[-1] == "/") else (target_dir + "/")
    target_file = '{}{}'.format(target_dir, re.sub(r'.+/', '', source_file))
    source_bucket, source_key = split_s3_path(source_file)
    target_dir_type = 's3' if (str(target_file)[0:2] == "s3") else 'local'
    print('Retrieving: {} to {}'.format(source_file, target_file))
    if target_dir_type == 's3':
        target_bucket, target_key = split_s3_path(target_file)
        try:
            s3.meta.client.copy(
                {
                    'Bucket': source_bucket,
                    'Key': source_key
                },
                target_bucket,
                target_key
            )
        except botocore.exceptions.ClientError as e:
            print(e.response['Error']['Message'])
    else:
        os.system("mkdir -p {}".format(os.path.dirname(target_file)))
        try:
            s3.Bucket(source_bucket).download_file(source_key, target_file)
        except botocore.exceptions.ClientError as e:
            print(e.response['Error']['Message'])

# Open S3 client
session = boto3.Session(aws_access_key_id=args.aws_access_key_id, aws_secret_access_key=args.aws_secret_access_key, region_name=args.aws_region_name)
s3 = session.resource('s3')

# Read wf arguments
with open(args.outputs_json) as f:
    outputs = json.load(f)

for key in outputs:
    if (type(outputs[key]) == list):
        for value in traverse(outputs[key]):
            if (str(value)[0:2] == "s3"):
                key_no_prefix = re.sub(r'.+\.', '', key)
                retrieve_file(value, '{}{}'.format(args.target_dir, key_no_prefix))
    else:
        if (str(outputs[key])[0:2] == "s3"):
            retrieve_file(outputs[key], args.target_dir)

